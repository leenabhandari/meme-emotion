{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube import YouTube\n",
    "import os\n",
    "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip\n",
    "from moviepy.editor import *\n",
    "import requests\n",
    "\n",
    "import pickle\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from tensorflow.keras.layers import Input, Embedding, SpatialDropout1D, LSTM\n",
    "from tensorflow.keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.layers import Bidirectional, Conv1D, Dense, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Button, HBox, VBox\n",
    "import pysrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = \"C:\\\\Users\\\\leena\\\\Desktop\\\\Python Projects\\\\emotion-from-tweet\\\\notebooks\"\n",
    "filename = \"video2.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(Path(os.path.join(os.path.abspath(''), '../')).resolve().as_posix())\n",
    "tokenizer_path = Path('../datasets/sentiment_analysis/tokenizer.pickle').resolve()\n",
    "with tokenizer_path.open('rb') as file:\n",
    "    tokenizer = pickle.load(file)\n",
    "\n",
    "input_dim = min(tokenizer.num_words, len(tokenizer.word_index) + 1)\n",
    "num_classes = 4\n",
    "embedding_dim = 500\n",
    "input_length = 100\n",
    "lstm_units = 128\n",
    "lstm_dropout = 0.1\n",
    "recurrent_dropout = 0.1\n",
    "spatial_dropout=0.2\n",
    "filters=64\n",
    "kernel_size=3\n",
    "\n",
    "input_layer = Input(shape=(input_length,))\n",
    "output_layer = Embedding(\n",
    "  input_dim=input_dim,\n",
    "  output_dim=embedding_dim,\n",
    "  input_shape=(input_length,)\n",
    ")(input_layer)\n",
    "\n",
    "output_layer = SpatialDropout1D(spatial_dropout)(output_layer)\n",
    "\n",
    "output_layer = Bidirectional(\n",
    "LSTM(lstm_units, return_sequences=True,\n",
    "     dropout=lstm_dropout, recurrent_dropout=recurrent_dropout)\n",
    ")(output_layer)\n",
    "output_layer = Conv1D(filters, kernel_size=kernel_size, padding='valid',\n",
    "                    kernel_initializer='glorot_uniform')(output_layer)\n",
    "\n",
    "avg_pool = GlobalAveragePooling1D()(output_layer)\n",
    "max_pool = GlobalMaxPooling1D()(output_layer)\n",
    "output_layer = concatenate([avg_pool, max_pool])\n",
    "\n",
    "output_layer = Dense(num_classes, activation='softmax')(output_layer)\n",
    "\n",
    "model = Model(input_layer, output_layer)\n",
    "\n",
    "model_weights_path = Path('../models/emotion_recognition/model_weights.h5').resolve()\n",
    "model.load_weights(model_weights_path.as_posix())\n",
    "encoder_path = Path('../models/emotion_recognition/encoder.pickle').resolve()\n",
    "with encoder_path.open('rb') as file:\n",
    "    encoder = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadVideo(link):\n",
    "    yt = YouTube(link)\n",
    "    stream = yt.streams.first()\n",
    "    out_file = stream.download(SAVE_PATH)\n",
    "    os.rename(out_file, filename)\n",
    "    print(\"Download successful - \" + str(out_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateCaptions(link,lang):\n",
    "    yt = YouTube(link)\n",
    "    print(yt.captions.all())\n",
    "    en_caption = yt.captions.get_by_language_code(lang)\n",
    "    en_caption_convert_to_srt =(en_caption.generate_srt_captions())\n",
    "    text_file = open(\"caption.srt\", \"w\")\n",
    "    text_file.write(en_caption_convert_to_srt)\n",
    "    text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseSubtitles():\n",
    "    sub = pysrt.open(\"caption.srt\")\n",
    "    global dialogs\n",
    "    global start\n",
    "    global end\n",
    "    dialogs = []\n",
    "    start = []\n",
    "    end = []\n",
    "    for obj in sub:\n",
    "        dialogs.append(obj.text)\n",
    "        start.append(obj.start.seconds)\n",
    "        end.append(obj.end.seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitVideo():\n",
    "    for i in range(len(dialogs)):\n",
    "        ffmpeg_extract_subclip(filename, start[i],end[i], targetname=dialogs[i][:8]+\".mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetchNews(country,category):\n",
    "    response = requests.get(\"http://newsapi.org/v2/top-headlines?country=\"+country+\"&category=\"+category+\"&apiKey=469e3b5dc7b44bf6ae90867fe0e8fd5c\")\n",
    "    data = response.json()\n",
    "    global articles\n",
    "    global news\n",
    "    news = []\n",
    "    articles = data['articles']\n",
    "    for article in articles:\n",
    "        print(article['title'])\n",
    "        title_parts = article['title'].split(\" - \")\n",
    "        text = title_parts[0] + article['description']\n",
    "        news.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateEmotion(selected):\n",
    "    sequences = [text.split() for text in selected]\n",
    "    list_tokenized = tokenizer.texts_to_sequences(sequences)\n",
    "    x_data = pad_sequences(list_tokenized, maxlen=100)\n",
    "\n",
    "    y_pred = model.predict(x_data)\n",
    "    emo = dict()\n",
    "    for index, value in enumerate(np.sum(y_pred, axis=0) / len(y_pred)):\n",
    "        print(encoder.classes_[index] + \": \" + str(value))\n",
    "        emo[encoder.classes_[index]]=value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_newlines(string, every=64):\n",
    "    return '\\n'.join(string[i:i+every] for i in range(0, len(string), every))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateFinalOutput(videoClip,text, dialog):\n",
    "    clip = VideoFileClip(videoClip)  \n",
    "    text = insert_newlines(text)\n",
    "    dialog = insert_newlines(dialog)\n",
    "    time = clip.duration\n",
    "    txt_clip = TextClip(text, fontsize = 22, color = 'white') \n",
    "    txt_clip2 = TextClip(dialog, fontsize = 15, color = 'yellow')\n",
    "    txt_clip = txt_clip.set_pos('top').set_duration(time) \n",
    "    txt_clip2 = txt_clip2.set_pos('bottom').set_duration(time) \n",
    "    video = CompositeVideoClip([clip, txt_clip,txt_clip2])  \n",
    "    video.write_videofile('Meme_'+videoClip[:8] + text[:8]+ '.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMeme(dialogs,news):\n",
    "    movie_line = 0\n",
    "    pairs = dict()\n",
    "    global_diff = 6\n",
    "    for j in range(len(dialogs)):\n",
    "        selected = dialogs[j]\n",
    "        sequences = [text.split() for text in selected]\n",
    "        list_tokenized = tokenizer.texts_to_sequences(sequences)\n",
    "        x_data = pad_sequences(list_tokenized, maxlen=100)\n",
    "\n",
    "        y_pred = model.predict(x_data)\n",
    "        emo = dict()\n",
    "        for index, value in enumerate(np.sum(y_pred, axis=0) / len(y_pred)):\n",
    "            print(encoder.classes_[index] + \": \" + str(value))\n",
    "            emo[encoder.classes_[index]]=value\n",
    "\n",
    "        min_diff = 3\n",
    "        news_line = 0\n",
    "        for i in range(len(news)):\n",
    "            cleaned_data = news[i]\n",
    "            sequences = [text.split() for text in cleaned_data]\n",
    "            list_tokenized = tokenizer.texts_to_sequences(sequences)\n",
    "            x_data = pad_sequences(list_tokenized, maxlen=100)\n",
    "\n",
    "            y_pred = model.predict(x_data)\n",
    "\n",
    "            cur_diff = 0\n",
    "            for index, value in enumerate(np.sum(y_pred, axis=0) / len(y_pred)):\n",
    "                cur_diff += abs(emo[encoder.classes_[index]] - value)\n",
    "\n",
    "            if cur_diff < min_diff:\n",
    "                news_line = i\n",
    "                min_diff = cur_diff\n",
    "\n",
    "        if min_diff < global_diff:\n",
    "            movie_line = j\n",
    "            global_diff = min_diff\n",
    "            \n",
    "        disp = articles[news_line]['title'] + \" : \" + dialogs[j]\n",
    "        print(articles[news_line]['title'] + \" : \" + dialogs[j] )\n",
    "        text = insert_newlines(disp,40)\n",
    "        generateFinalOutput(dialogs[j][:8] + '.mp4', articles[news_line]['title'], dialogs[j] )\n",
    "        pairs[j] = news_line\n",
    "    \n",
    "    print(\"Final Output --> \"+ news[pairs[movie_line]] + \" : \" + dialogs[movie_line])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDialogMeme(selected,file):\n",
    "    sequences = [text.split() for text in selected]\n",
    "    list_tokenized = tokenizer.texts_to_sequences(sequences)\n",
    "    x_data = pad_sequences(list_tokenized, maxlen=100)\n",
    "\n",
    "    y_pred = model.predict(x_data)\n",
    "    emo = dict()\n",
    "    for index, value in enumerate(np.sum(y_pred, axis=0) / len(y_pred)):\n",
    "        print(encoder.classes_[index] + \": \" + str(value))\n",
    "        emo[encoder.classes_[index]]=value\n",
    "        \n",
    "    min_diff = 5\n",
    "    ans = 0\n",
    "    for i in range(len(news)):\n",
    "        cleaned_data = news[i]\n",
    "        sequences = [text.split() for text in cleaned_data]\n",
    "        list_tokenized = tokenizer.texts_to_sequences(sequences)\n",
    "        x_data = pad_sequences(list_tokenized, maxlen=100)\n",
    "\n",
    "        y_pred = model.predict(x_data)\n",
    "\n",
    "        cur_diff = 0\n",
    "        for index, value in enumerate(np.sum(y_pred, axis=0) / len(y_pred)):\n",
    "            cur_diff += abs(emo[encoder.classes_[index]] - value)\n",
    "\n",
    "        if cur_diff < min_diff:\n",
    "            ans = i\n",
    "            min_diff = cur_diff\n",
    "            \n",
    "    print(news[ans] + \" : \" + selected)\n",
    "    generateFinalOutput(file, news[ans], selected )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demoInfinityWarTrailer():\n",
    "    link = \"https://www.youtube.com/watch?v=6ZfuNTqbHE8&t\"\n",
    "    print(\"Downloading video...\")\n",
    "    downloadVideo(link)\n",
    "    subs = \"There was an idea, to bring together a group of remarkable people, to see if we could become something more. So when they needed us we could fight the battles that they never could. In time, you'll know what it's like to lose. To feel so desperately that you're right, that you fail all the same. Dread it, Run from it. Destiny still arrives. Evacuate the city. Engage all defences and get this man a shield. Fun isn't something one considers the balance in the universe. But this does put a smile on my face. Who the hell are you guys?\"\n",
    "    global dialogs\n",
    "    global start\n",
    "    global end\n",
    "    dialogs = subs.split(\". \")\n",
    "    start=[4,20,45,51,61,67,77,80,97,104,135]\n",
    "    end=[18,29,50,56,66,71,79,86,102,111,139]\n",
    "    print(\"Splitting video...\")\n",
    "    splitVideo()\n",
    "    print(\"Fetching news...\")\n",
    "    fetchNews('in','entertainment')\n",
    "    print(\"Generating all Memes...\")\n",
    "    getMeme(dialogs,news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textYoutubeLink = widgets.Text(\n",
    "    placeholder='Enter youtube video link',\n",
    "    description='Youtube: ',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "def clickedDownload(arg): \n",
    "    downloadVideo(textYoutubeLink.value)\n",
    "    \n",
    "button_download = Button(description = 'Download Video')   \n",
    "button_download.on_click(clickedDownload)\n",
    "\n",
    "def clickedSplit(arg):\n",
    "    generateCaptions(textYoutubeLink.value,'en')\n",
    "    parseSubtitles()\n",
    "    splitVideo()\n",
    "    print(\"Video splitting successful!\")\n",
    "    \n",
    "button_split = Button(description = 'Split Video')   \n",
    "button_split.on_click(clickedSplit)\n",
    "\n",
    "selCountry = widgets.Select(options=['ae','ar','at','au','be','bg','br','ca','ch','cn','co','cu','cz','de','eg','fr','gb','gr','hk','hu','id','ie','il','in','it','jp','kr','lt','lv','ma','mx','my','ng','nl','no','nz','ph','pl','pt','ro','rs','ru','sa','se','sg','si','sk','th','tr','tw','ua','us','ve','za'],value = 'in', rows = 1, description = 'Country: ')\n",
    "selCategory = widgets.Select(options=['business','entertainment','general','health','science','sports','technology'],value = 'entertainment', rows = 7, description = 'Category: ')\n",
    "\n",
    "def clickedNews(arg): \n",
    "    fetchNews(selCountry.value,selCategory.value)\n",
    "    \n",
    "button_news = Button(description = 'Fetch News')   \n",
    "button_news.on_click(clickedNews)\n",
    "\n",
    "def clickedFull(arg):\n",
    "    demoInfinityWarTrailer()\n",
    "    \n",
    "button_demo = Button(description = 'Generate All Memes')   \n",
    "button_demo.on_click(clickedFull)\n",
    "\n",
    "textFilename = widgets.Text(\n",
    "    value=filename,\n",
    "    placeholder='Enter file name',\n",
    "    description='File Name: ',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "dialog_text = \"But this does put a smile on my face.\"\n",
    "def clickedOneMeme(arg): \n",
    "    getDialogMeme(txtml.value,textFilename.value)\n",
    "\n",
    "txtml = widgets.Textarea(value=dialog_text,placeholder = \"Type the dialog\", description = \"Enter dialog: \")\n",
    "button_meme = Button(description = 'Generate Meme')   \n",
    "button_meme.on_click(clickedOneMeme)\n",
    "\n",
    "txtCustom = widgets.Textarea(placeholder = \"Custom Meme line\", description = \"Enter line: \")\n",
    "def clickedCustom(arg): \n",
    "    generateFinalOutput(textFilename.value, txtCustom.value, txtml.value )\n",
    "    \n",
    "button_custom = Button(description = 'Custom Meme')   \n",
    "button_custom.on_click(clickedCustom)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"video3.mp4\"\n",
    "print(\"Meme Builder Dashboard\")\n",
    "display(button_demo)\n",
    "display(HBox([textYoutubeLink,button_download,button_split]))\n",
    "display(selCategory)\n",
    "display(selCountry)\n",
    "display(button_news)\n",
    "#display(txtml)\n",
    "display(HBox([txtml,textFilename,button_meme]))\n",
    "display(HBox([txtCustom,button_custom]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
