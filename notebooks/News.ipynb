{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\"http://newsapi.org/v2/top-headlines?country=in&category=entertainment&apiKey=469e3b5dc7b44bf6ae90867fe0e8fd5c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = data['articles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = []\n",
    "for article in articles:\n",
    "    title_parts = article['title'].split(\" - \")\n",
    "    text = title_parts[0] + article['description']\n",
    "    news.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\leena\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(Path(os.path.join(os.path.abspath(''), '../')).resolve().as_posix())\n",
    "import pickle\n",
    "\n",
    "tokenizer_path = Path('../datasets/sentiment_analysis/tokenizer.pickle').resolve()\n",
    "with tokenizer_path.open('rb') as file:\n",
    "    tokenizer = pickle.load(file)\n",
    "\n",
    "from tensorflow.keras.layers import Input, Embedding, SpatialDropout1D, LSTM\n",
    "from tensorflow.keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.layers import Bidirectional, Conv1D, Dense, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "input_dim = min(tokenizer.num_words, len(tokenizer.word_index) + 1)\n",
    "num_classes = 4\n",
    "embedding_dim = 500\n",
    "input_length = 100\n",
    "lstm_units = 128\n",
    "lstm_dropout = 0.1\n",
    "recurrent_dropout = 0.1\n",
    "spatial_dropout=0.2\n",
    "filters=64\n",
    "kernel_size=3\n",
    "\n",
    "input_layer = Input(shape=(input_length,))\n",
    "output_layer = Embedding(\n",
    "  input_dim=input_dim,\n",
    "  output_dim=embedding_dim,\n",
    "  input_shape=(input_length,)\n",
    ")(input_layer)\n",
    "\n",
    "output_layer = SpatialDropout1D(spatial_dropout)(output_layer)\n",
    "\n",
    "output_layer = Bidirectional(\n",
    "LSTM(lstm_units, return_sequences=True,\n",
    "     dropout=lstm_dropout, recurrent_dropout=recurrent_dropout)\n",
    ")(output_layer)\n",
    "output_layer = Conv1D(filters, kernel_size=kernel_size, padding='valid',\n",
    "                    kernel_initializer='glorot_uniform')(output_layer)\n",
    "\n",
    "avg_pool = GlobalAveragePooling1D()(output_layer)\n",
    "max_pool = GlobalMaxPooling1D()(output_layer)\n",
    "output_layer = concatenate([avg_pool, max_pool])\n",
    "\n",
    "output_layer = Dense(num_classes, activation='softmax')(output_layer)\n",
    "\n",
    "model = Model(input_layer, output_layer)\n",
    "\n",
    "model_weights_path = Path('../models/emotion_recognition/model_weights.h5').resolve()\n",
    "model.load_weights(model_weights_path.as_posix())\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "encoder_path = Path('../models/emotion_recognition/encoder.pickle').resolve()\n",
    "with encoder_path.open('rb') as file:\n",
    "    encoder = pickle.load(file)\n",
    "    \n",
    "from nlp import preprocess\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = \"There was an idea, to bring together a group of remarkable people, to see if we could become something more. So when they needed us we could fight the battles that they never could. In time, you'll know what it's like to lose. To feel so desperately that you're right, that to fail all the same. Dread it, Run from it. Destiny still arrives. Evacuate the city. Engage all defences and get this man a shield. Fun isn't something one considers the balance in the universe. But this does put a smile on my face. Who the hell are you guys?\"\n",
    "dialogs = subs.split(\". \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anger: 0.13067813\n",
      "fear: 0.7585651\n",
      "joy: 0.021767307\n",
      "sadness: 0.08898952\n"
     ]
    }
   ],
   "source": [
    "selected = dialogs[9]\n",
    "sequences = [text.split() for text in selected]\n",
    "list_tokenized = tokenizer.texts_to_sequences(sequences)\n",
    "x_data = pad_sequences(list_tokenized, maxlen=100)\n",
    "\n",
    "y_pred = model.predict(x_data)\n",
    "emo = dict()\n",
    "for index, value in enumerate(np.sum(y_pred, axis=0) / len(y_pred)):\n",
    "    print(encoder.classes_[index] + \": \" + str(value))\n",
    "    emo[encoder.classes_[index]]=value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_diff = 5\n",
    "ans = 0\n",
    "for i in range(len(news)):\n",
    "    cleaned_data = news[i]\n",
    "    sequences = [text.split() for text in cleaned_data]\n",
    "    list_tokenized = tokenizer.texts_to_sequences(sequences)\n",
    "    x_data = pad_sequences(list_tokenized, maxlen=100)\n",
    "\n",
    "    y_pred = model.predict(x_data)\n",
    "    \n",
    "    cur_diff = 0\n",
    "    for index, value in enumerate(np.sum(y_pred, axis=0) / len(y_pred)):\n",
    "        cur_diff += abs(emo[encoder.classes_[index]] - value)\n",
    "\n",
    "    if cur_diff < min_diff:\n",
    "        ans = i\n",
    "        min_diff = cur_diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amitabh Bachchan hangs 'nimbu mirchi' on 2021 to protect it from evil eyeMegastar Amitabh Bachchan on Tuesday shared a quirky post in an attempt to protect the year 2021 from the evil eye. : But this does put a smile on my face\n"
     ]
    }
   ],
   "source": [
    "print(news[ans] + \" : \" + selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anger: 0.13310911\n",
      "fear: 0.7552341\n",
      "joy: 0.021626506\n",
      "sadness: 0.090030156\n"
     ]
    }
   ],
   "source": [
    "cleaned_data = news[1]\n",
    "sequences = [text.split() for text in cleaned_data]\n",
    "list_tokenized = tokenizer.texts_to_sequences(sequences)\n",
    "x_data = pad_sequences(list_tokenized, maxlen=100)\n",
    "\n",
    "y_pred = model.predict(x_data)\n",
    "for index, value in enumerate(np.sum(y_pred, axis=0) / len(y_pred)):\n",
    "    print(encoder.classes_[index] + \": \" + str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMeme(dialogs,news):\n",
    "    movie_line = 0\n",
    "    pairs = dict()\n",
    "    global_diff = 6\n",
    "    for j in range(len(dialogs)):\n",
    "        selected = dialogs[j]\n",
    "        sequences = [text.split() for text in selected]\n",
    "        list_tokenized = tokenizer.texts_to_sequences(sequences)\n",
    "        x_data = pad_sequences(list_tokenized, maxlen=100)\n",
    "\n",
    "        y_pred = model.predict(x_data)\n",
    "        emo = dict()\n",
    "        for index, value in enumerate(np.sum(y_pred, axis=0) / len(y_pred)):\n",
    "            print(encoder.classes_[index] + \": \" + str(value))\n",
    "            emo[encoder.classes_[index]]=value\n",
    "\n",
    "        min_diff = 3\n",
    "        news_line = 0\n",
    "        for i in range(len(news)):\n",
    "            cleaned_data = news[i]\n",
    "            sequences = [text.split() for text in cleaned_data]\n",
    "            list_tokenized = tokenizer.texts_to_sequences(sequences)\n",
    "            x_data = pad_sequences(list_tokenized, maxlen=100)\n",
    "\n",
    "            y_pred = model.predict(x_data)\n",
    "\n",
    "            cur_diff = 0\n",
    "            for index, value in enumerate(np.sum(y_pred, axis=0) / len(y_pred)):\n",
    "                cur_diff += abs(emo[encoder.classes_[index]] - value)\n",
    "\n",
    "            if cur_diff < min_diff:\n",
    "                news_line = i\n",
    "                min_diff = cur_diff\n",
    "\n",
    "        if min_diff < global_diff:\n",
    "            movie_line = j\n",
    "            global_diff = min_diff\n",
    "            \n",
    "        print(articles[news_line]['title'] + \" : \" + dialogs[j] )\n",
    "        pairs[j] = news_line\n",
    "    \n",
    "    print(\"Final Output --> \"+ news[pairs[movie_line]] + \" : \" + dialogs[movie_line])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anger: 0.13230877\n",
      "fear: 0.75031745\n",
      "joy: 0.020764206\n",
      "sadness: 0.0966099\n",
      "Monal Misses Top 5, But Takes Home Rs 50 Lakh!.. - Greatandhra.com : There was an idea, to bring together a group of remarkable people, to see if we could become something more\n",
      "anger: 0.13240752\n",
      "fear: 0.75724274\n",
      "joy: 0.022118635\n",
      "sadness: 0.08823136\n",
      "Amitabh Bachchan hangs 'nimbu mirchi' on 2021 to protect it from evil eye - Times of India : So when they needed us we could fight the battles that they never could\n",
      "anger: 0.13177775\n",
      "fear: 0.7610933\n",
      "joy: 0.022968303\n",
      "sadness: 0.0841608\n",
      "Amitabh Bachchan hangs 'nimbu mirchi' on 2021 to protect it from evil eye - Times of India : In time, you'll know what it's like to lose\n",
      "anger: 0.13157234\n",
      "fear: 0.7553917\n",
      "joy: 0.021886934\n",
      "sadness: 0.09114935\n",
      "Photos of celebrities at airport Pics | Photos of celebrities at airport Photos | Photos of celebrities at airport Portfolio Pics | Photos of celebrities at airport Personal Photos - ETimes Photogallery - Times of India : To feel so desperately that you're right, that to fail all the same\n",
      "anger: 0.13294794\n",
      "fear: 0.75034225\n",
      "joy: 0.020553686\n",
      "sadness: 0.096156076\n",
      "Monal Misses Top 5, But Takes Home Rs 50 Lakh!.. - Greatandhra.com : Dread it, Run from it\n",
      "anger: 0.13421217\n",
      "fear: 0.7557998\n",
      "joy: 0.021604886\n",
      "sadness: 0.08838318\n",
      "Shilpa Shirodkar Says Brother-in-law Mahesh Babu is Sometimes There for Her More Than Sister Namrata - News18 : Destiny still arrives\n",
      "anger: 0.1333073\n",
      "fear: 0.75831497\n",
      "joy: 0.022379177\n",
      "sadness: 0.08599846\n",
      "Amitabh Bachchan hangs 'nimbu mirchi' on 2021 to protect it from evil eye - Times of India : Evacuate the city\n",
      "anger: 0.1350403\n",
      "fear: 0.7442698\n",
      "joy: 0.020878615\n",
      "sadness: 0.09981136\n",
      "Bigg Boss 14: Vikas Gupta Ousted From The Show For Pushing Arshi Khan Into The Pool - NDTV : Engage all defences and get this man a shield\n",
      "anger: 0.1340147\n",
      "fear: 0.75192827\n",
      "joy: 0.021538613\n",
      "sadness: 0.092518605\n",
      "Chitra’s husband Hemanth arrested - The Indian Express : Fun isn't something one considers the balance in the universe\n",
      "anger: 0.13067813\n",
      "fear: 0.7585651\n",
      "joy: 0.021767307\n",
      "sadness: 0.08898952\n",
      "Amitabh Bachchan hangs 'nimbu mirchi' on 2021 to protect it from evil eye - Times of India : But this does put a smile on my face\n",
      "anger: 0.13135451\n",
      "fear: 0.75693786\n",
      "joy: 0.022167336\n",
      "sadness: 0.08954038\n",
      "Amitabh Bachchan hangs 'nimbu mirchi' on 2021 to protect it from evil eye - Times of India : Who the hell are you guys?\n",
      "Final Output --> Amitabh Bachchan hangs 'nimbu mirchi' on 2021 to protect it from evil eyeMegastar Amitabh Bachchan on Tuesday shared a quirky post in an attempt to protect the year 2021 from the evil eye. : So when they needed us we could fight the battles that they never could\n"
     ]
    }
   ],
   "source": [
    "getMeme(dialogs,news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
