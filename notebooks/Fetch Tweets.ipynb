{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch Tweets\n",
    "\n",
    "Donwload and save tweets, using a **query** value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "env_path = Path('../.env').resolve()\n",
    "load_dotenv(dotenv_path=env_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API access\n",
    "\n",
    "First of all, we'll connect to the Twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = os.getenv(\"CONSUMER_KEY\")\n",
    "consumer_secret = os.getenv(\"CONSUMER_SECRET\")\n",
    "access_token = os.getenv(\"ACCESS_TOKEN\")\n",
    "access_token_secret = os.getenv(\"ACCESS_TOKEN_SECRET\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tweepy import OAuthHandler, API, TweepError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to the Twitter API.\n"
     ]
    }
   ],
   "source": [
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = API(auth)\n",
    "print('Successfully connected to the Twitter API.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Tweets\n",
    "\n",
    "Now we can define our query and search for the tweets containing it.\n",
    "\n",
    "- **query**: *hashtag* or *emoji* that will be used to fetch the tweets\n",
    "- **max_requests**: Maximum number of requests to the API.\n",
    "    - Restriction: 180 requests / 15 min window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '#witty'\n",
    "max_requests = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts aliases to the real emoji representation (e.g. :thumbs_up: => üëç)\n",
    "\n",
    "from emoji import emojize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = emojize(query) + ' -filter:retweets'\n",
    "searched_tweets = []\n",
    "last_id = -1\n",
    "request_count = 0\n",
    "while request_count < max_requests:\n",
    "    try:\n",
    "        new_tweets = api.search(q=q,\n",
    "                                lang='en',\n",
    "                                count=100,\n",
    "                                max_id=str(last_id - 1),\n",
    "                                tweet_mode='extended')\n",
    "        if not new_tweets:\n",
    "            break\n",
    "        searched_tweets.extend(new_tweets)\n",
    "        last_id = new_tweets[-1].id\n",
    "        request_count += 1\n",
    "    except TweepError as e:\n",
    "        print(e)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format and save\n",
    "\n",
    "Format the API data to the desired structure and save a `.csv` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216 #witty tweets\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for tweet in searched_tweets:\n",
    "    data.append([tweet.id, tweet.created_at, tweet.user.screen_name, tweet.full_text])\n",
    "df = pd.DataFrame(data=data, columns=['id', 'date', 'user', 'text'])\n",
    "print(str(len(data)) + ' ' + query + ' tweets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1338550821454295055</td>\n",
       "      <td>2020-12-14 18:25:59</td>\n",
       "      <td>BlackCloud1966</td>\n",
       "      <td>You FAILED on this vaccine hype.\\n#Witty\\nSo w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1338526755410284545</td>\n",
       "      <td>2020-12-14 16:50:21</td>\n",
       "      <td>paraelwhatsapp</td>\n",
       "      <td>ornaments via /r/funny https://t.co/Y1HiXq2gd9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1338526747130814467</td>\n",
       "      <td>2020-12-14 16:50:19</td>\n",
       "      <td>paraelwhatsapp</td>\n",
       "      <td>Between Two Ferns bloobers are hilarious and w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1338511666745630730</td>\n",
       "      <td>2020-12-14 15:50:24</td>\n",
       "      <td>paraelwhatsapp</td>\n",
       "      <td>Husky (metal) Breakdown via /r/funny https://t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1338511660412231683</td>\n",
       "      <td>2020-12-14 15:50:22</td>\n",
       "      <td>paraelwhatsapp</td>\n",
       "      <td>Once you see Cookie Monster, you can‚Äôt unsee i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                date            user  \\\n",
       "0  1338550821454295055 2020-12-14 18:25:59  BlackCloud1966   \n",
       "1  1338526755410284545 2020-12-14 16:50:21  paraelwhatsapp   \n",
       "2  1338526747130814467 2020-12-14 16:50:19  paraelwhatsapp   \n",
       "3  1338511666745630730 2020-12-14 15:50:24  paraelwhatsapp   \n",
       "4  1338511660412231683 2020-12-14 15:50:22  paraelwhatsapp   \n",
       "\n",
       "                                                text  \n",
       "0  You FAILED on this vaccine hype.\\n#Witty\\nSo w...  \n",
       "1  ornaments via /r/funny https://t.co/Y1HiXq2gd9...  \n",
       "2  Between Two Ferns bloobers are hilarious and w...  \n",
       "3  Husky (metal) Breakdown via /r/funny https://t...  \n",
       "4  Once you see Cookie Monster, you can‚Äôt unsee i...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved under: \"C:/Users/leena/Desktop/Python Projects/emotion-from-tweet/datasets/tweepy\"\n"
     ]
    }
   ],
   "source": [
    "PATH = Path('../datasets/tweepy').resolve()\n",
    "filename = query + '.csv'\n",
    "df.to_csv(os.path.join(PATH, filename), index=None)\n",
    "print('Saved under: \"' + PATH.as_posix() + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
